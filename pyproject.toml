[project]
name = "litellm"
version = "1.75.5"
description = "Library to easily interface with LLM API providers"
authors = [{ name = "BerriAI" }]
requires-python = ">=3.8.1,<4.0, !=3.9.7"
readme = "README.md"
license = "MIT"
dependencies = [
    "httpx>=0.23.0",
    "openai>=1.68.2",
    "python-dotenv>=0.2.0",
    "tiktoken>=0.7.0",
    "importlib-metadata>=6.8.0",
    "tokenizers",
    "click",
    "jinja2>=3.1.2,<4",
    "aiohttp>=3.10",
    "pydantic>=2.5.0,<3",
    "jsonschema>=4.22.0,<5",
]

[project.optional-dependencies]
proxy = [
    "gunicorn>=23.0.0,<24",
    "uvicorn>=0.29.0,<0.30",
    "uvloop>=0.21.0,<0.22 ; sys_platform != 'win32'",
    "fastapi>=0.115.5,<0.116",
    "backoff",
    "pyyaml>=6.0.1,<7",
    "rq",
    "orjson>=3.9.7,<4",
    "apscheduler>=3.10.4,<4",
    "fastapi-sso>=0.16.0,<0.17",
    "PyJWT>=2.8.0,<3",
    "python-multipart>=0.0.18,<0.0.19",
    "cryptography>=43.0.1,<44",
    "pynacl>=1.5.0,<2",
    "websockets>=13.1.0,<14",
    "boto3==1.34.34",
    "azure-identity>=1.15.0,<2",
    "azure-storage-blob>=12.25.1,<13",
    "mcp>=1.10.0,<2 ; python_version >= '3.10'",
    "litellm-proxy-extras==0.2.15",
    "litellm-enterprise==0.1.17",
    "rich==13.7.1",
    "polars>=1.31.0,<2 ; python_version >= '3.10'",
]
extra_proxy = [
    "prisma==0.11.0",
    "azure-identity>=1.15.0,<2",
    "azure-keyvault-secrets>=4.8.0,<5",
    "google-cloud-kms>=2.21.3,<3",
    "resend>=0.8.0,<0.9",
    "redisvl>=0.4.1,<0.5 ; python_version >= '3.9' and python_version < '3.14'",
]
utils = ["numpydoc"]
caching = ["diskcache>=5.6.1,<6"]
semantic-router = ["semantic-router ; python_version >= '3.9'"]
mlflow = ["mlflow>3.1.4 ; python_version >= '3.10'"]

[project.urls]
homepage = "https://litellm.ai"
Homepage = "https://litellm.ai"
repository = "https://github.com/BerriAI/litellm"
Repository = "https://github.com/BerriAI/litellm"
documentation = "https://docs.litellm.ai"
Documentation = "https://docs.litellm.ai"

[project.scripts]
litellm = "litellm:run_server"
litellm-proxy = "litellm.proxy.client.cli:cli"

[dependency-groups]
dev = [
    "flake8>=6.1.0,<7",
    "black>=23.12.0,<24",
    "mypy~=1.0",
    "pytest>=7.4.3,<8",
    "pytest-mock>=3.12.0,<4",
    "pytest-asyncio>=0.21.1,<0.22",
    "requests-mock>=1.12.1,<2",
    "responses>=0.25.7,<0.26",
    "respx>=0.22.0,<0.23",
    "ruff>=0.1.0,<0.2",
    "types-requests",
    "types-setuptools",
    "types-redis",
    "types-PyYAML",
    "opentelemetry-api==1.25.0",
    "opentelemetry-sdk==1.25.0",
    "opentelemetry-exporter-otlp==1.25.0",
    "langfuse>=2.45.0,<3",
]
proxy-dev = [
    "prisma==0.11.0",
    "hypercorn>=0.15.0,<0.16",
    "prometheus-client==0.20.0",
    "opentelemetry-api==1.25.0",
    "opentelemetry-sdk==1.25.0",
    "opentelemetry-exporter-otlp==1.25.0",
    "azure-identity>=1.15.0,<2",
]

[tool.uv]
default-groups = [
    "dev",
    "proxy-dev",
]

[tool.hatch.build.targets.sdist]
include = [
    "litellm",
    "litellm/py.typed",
]

[tool.hatch.build.targets.wheel]
include = [
    "litellm",
    "litellm/py.typed",
]

[tool.poetry.urls]
homepage = "https://litellm.ai"
Homepage = "https://litellm.ai"
repository = "https://github.com/BerriAI/litellm"
Repository = "https://github.com/BerriAI/litellm"
documentation = "https://docs.litellm.ai"
Documentation = "https://docs.litellm.ai"

[tool.poetry.dependencies]
python = ">=3.8.1,<4.0, !=3.9.7"
httpx = ">=0.23.0"
openai = ">=1.99.5"
python-dotenv = ">=0.2.0"
tiktoken = ">=0.7.0"
importlib-metadata = ">=6.8.0"
tokenizers = "*"
click = "*"
jinja2 = "^3.1.2"
aiohttp = ">=3.10"
pydantic = "^2.5.0"
jsonschema = "^4.22.0"
numpydoc = {version = "*", optional = true} # used in utils.py

uvicorn = {version = "^0.29.0", optional = true}
uvloop = {version = "^0.21.0", optional = true, markers="sys_platform != 'win32'"}
gunicorn = {version = "^23.0.0", optional = true}
fastapi = {version = "^0.115.5", optional = true}
backoff = {version = "*", optional = true}
pyyaml = {version = "^6.0.1", optional = true}
rq = {version = "*", optional = true}
orjson = {version = "^3.9.7", optional = true}
apscheduler = {version = "^3.10.4", optional = true}
fastapi-sso = { version = "^0.16.0", optional = true }
PyJWT = { version = "^2.8.0", optional = true }
python-multipart = { version = "^0.0.18", optional = true}
cryptography = {version = "^43.0.1", optional = true}
prisma = {version = "0.11.0", optional = true}
azure-identity = {version = "^1.15.0", optional = true}
azure-keyvault-secrets = {version = "^4.8.0", optional = true}
azure-storage-blob = {version="^12.25.1", optional=true}
google-cloud-kms = {version = "^2.21.3", optional = true}
google-cloud-iam = {version = "^2.19.1", optional = true}
resend = {version = "^0.8.0", optional = true}
pynacl = {version = "^1.5.0", optional = true}
websockets = {version = "^13.1.0", optional = true}
boto3 = {version = "1.34.34", optional = true}
redisvl = {version = "^0.4.1", optional = true, markers = "python_version >= '3.9' and python_version < '3.14'"}
mcp = {version = "^1.10.0", optional = true, python = ">=3.10"}
litellm-proxy-extras = {version = "0.2.16", optional = true}
rich = {version = "13.7.1", optional = true}
litellm-enterprise = {version = "0.1.19", optional = true}
diskcache = {version = "^5.6.1", optional = true}
polars = {version = "^1.31.0", optional = true, python = ">=3.10"}
semantic-router = {version = "*", optional = true, python = ">=3.9"}
mlflow = {version = ">3.1.4", optional = true, python = ">=3.10"}

[tool.poetry.extras]
proxy = [
    "gunicorn",
    "uvicorn",
    "uvloop",
    "fastapi",
    "backoff",
    "pyyaml",
    "rq",
    "orjson",
    "apscheduler",
    "fastapi-sso",
    "PyJWT",
    "python-multipart",
    "cryptography",
    "pynacl",
    "websockets",
    "boto3",
    "azure-identity",
    "azure-storage-blob",
    "mcp",
    "litellm-proxy-extras",
    "litellm-enterprise",
    "rich",
    "polars",
]

extra_proxy = [
    "prisma",
    "azure-identity",
    "azure-keyvault-secrets",
    "google-cloud-kms",
    "google-cloud-iam",
    "resend",
    "redisvl"
]

utils = [
    "numpydoc",
]

caching = ["diskcache"]

semantic-router = ["semantic-router"]

mlflow = ["mlflow"]

[tool.isort]
profile = "black"

[tool.poetry.scripts]
litellm = 'litellm:run_server'
litellm-proxy = 'litellm.proxy.client.cli:cli'

[tool.poetry.group.dev.dependencies]
flake8 = "^6.1.0"
black = "^23.12.0"
mypy = "^1.0"
pytest = "^7.4.3"
pytest-mock = "^3.12.0"
pytest-asyncio = "^0.21.1"
requests-mock = "^1.12.1"
responses = "^0.25.7"
respx = "^0.22.0"
ruff = "^0.1.0"
types-requests = "*"
types-setuptools = "*"
types-redis = "*"
types-PyYAML = "*"
opentelemetry-api = "1.25.0"
opentelemetry-sdk = "1.25.0"
opentelemetry-exporter-otlp = "1.25.0"
langfuse = "^2.45.0"

[tool.poetry.group.proxy-dev.dependencies]
prisma = "0.11.0"
hypercorn = "^0.15.0"
prometheus-client = "0.20.0"
opentelemetry-api = "1.25.0"
opentelemetry-sdk = "1.25.0"
opentelemetry-exporter-otlp = "1.25.0"
azure-identity = "^1.15.0"

[build-system]
requires = ["poetry-core", "wheel"]
build-backend = "poetry.core.masonry.api"

[tool.commitizen]
version = "1.75.5"
version_files = [
    "pyproject.toml:^version"
]

[tool.mypy]
plugins = "pydantic.mypy"
